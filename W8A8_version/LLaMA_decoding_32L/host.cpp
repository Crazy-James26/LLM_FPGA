//=============================================================================
// Auto generated by Allo
//=============================================================================

// OpenCL utility layer include
#include "xcl2.hpp"
#include <ap_int.h>
#include <algorithm>
#include <cstdio>
#include <random>
#include <vector>
#include <iomanip>

// HBM channels
#define MAX_HBM_CHANNEL_COUNT 32
#define CHANNEL_NAME(n) n | XCL_MEM_TOPOLOGY
const int HBM[MAX_HBM_CHANNEL_COUNT] = {
    CHANNEL_NAME(0),  CHANNEL_NAME(1),  CHANNEL_NAME(2),  CHANNEL_NAME(3),  CHANNEL_NAME(4),
    CHANNEL_NAME(5),  CHANNEL_NAME(6),  CHANNEL_NAME(7),  CHANNEL_NAME(8),  CHANNEL_NAME(9),
    CHANNEL_NAME(10), CHANNEL_NAME(11), CHANNEL_NAME(12), CHANNEL_NAME(13), CHANNEL_NAME(14),
    CHANNEL_NAME(15), CHANNEL_NAME(16), CHANNEL_NAME(17), CHANNEL_NAME(18), CHANNEL_NAME(19),
    CHANNEL_NAME(20), CHANNEL_NAME(21), CHANNEL_NAME(22), CHANNEL_NAME(23), CHANNEL_NAME(24),
    CHANNEL_NAME(25), CHANNEL_NAME(26), CHANNEL_NAME(27), CHANNEL_NAME(28), CHANNEL_NAME(29),
    CHANNEL_NAME(30), CHANNEL_NAME(31)};

const int DDR[2] = {CHANNEL_NAME(32), CHANNEL_NAME(33)};

int main(int argc, char** argv) {
    if (argc != 2) {
        std::cout << "Usage: " << argv[0] << " <XCLBIN File>" << std::endl;
        return EXIT_FAILURE;
    }

    std::string binaryFile = argv[1];
    cl_int err;
    cl::CommandQueue q;
    cl::Context context;
    cl::Program program;
    cl::Kernel krnl_Bert_layer_dataflow_region_1;
    cl::Kernel krnl_Bert_layer_dataflow_region_2;
    cl::Kernel krnl_Bert_layer_dataflow_region_3;
    // Allocate Memory in Host Memory
    // When creating a buffer with user pointer (CL_MEM_USE_HOST_PTR), under the
    // hood user ptr is used if it is properly aligned. when not aligned, runtime had no choice
    // but to create its own host side buffer. So it is recommended to use this allocator if
    // user wish to create buffer using CL_MEM_USE_HOST_PTR to align user buffer to page
    // boundary. It will ensure that user buffer is used when user create Buffer/Mem object with
    // CL_MEM_USE_HOST_PTR
    size_t size_bytes_in0 = sizeof(float) * 4096;
    std::vector<float, aligned_allocator<float > > source_in0(4096);
    
    size_t size_bytes_wk_0 = sizeof(ap_uint<512>) * 32*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_wk_0(32*4096);
    size_t size_bytes_wk_1 = sizeof(ap_uint<512>) * 32*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_wk_1(32*4096);
    size_t size_bytes_wv_0 = sizeof(ap_uint<512>) * 32*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_wv_0(32*4096);
    size_t size_bytes_wv_1 = sizeof(ap_uint<512>) * 32*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_wv_1(32*4096);
    size_t size_bytes_wq_0 = sizeof(ap_uint<512>) * 32*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_wq_0(32*4096);
    size_t size_bytes_wq_1 = sizeof(ap_uint<512>) * 32*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_wq_1(32*4096);

    size_t size_bytes_w_ds0_0 = sizeof(ap_uint<512>) * 32*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_w_ds0_0(32*4096);
    size_t size_bytes_w_ds0_1 = sizeof(ap_uint<512>) * 32*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_w_ds0_1(32*4096);

    size_t size_bytes_w_ds1_0 = sizeof(ap_uint<512>) * 43*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_w_ds1_0(43*4096);
    size_t size_bytes_w_ds1_1 = sizeof(ap_uint<512>) * 43*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_w_ds1_1(43*4096);
    size_t size_bytes_w_ds1_2 = sizeof(ap_uint<512>) * 43*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_w_ds1_2(43*4096);
    size_t size_bytes_w_ds1_3 = sizeof(ap_uint<512>) * 43*4096;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_w_ds1_3(43*4096);

    size_t size_bytes_w_ds2_0 = sizeof(ap_uint<512>) * 16*11008;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_w_ds2_0(16*11008);
    size_t size_bytes_w_ds2_1 = sizeof(ap_uint<512>) * 16*11008;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_w_ds2_1(16*11008);
    size_t size_bytes_w_ds2_2 = sizeof(ap_uint<512>) * 16*11008;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_w_ds2_2(16*11008);
    size_t size_bytes_w_ds2_3 = sizeof(ap_uint<512>) * 16*11008;
    std::vector<ap_uint<512>, aligned_allocator<ap_uint<512> > > source_w_ds2_3(16*11008);

    size_t size_bytes_out0 = sizeof(float) * 4096;
    std::vector<float, aligned_allocator<float > > source_out0(4096);

    // OPENCL HOST CODE AREA START
    // get_xil_devices() is a utility API which will find the xilinx
    // platforms and will return list of devices connected to Xilinx platform
    auto devices = xcl::get_xil_devices();
    // read_binary_file() is a utility API which will load the binaryFile
    // and will return the pointer to file buffer.
    auto fileBuf = xcl::read_binary_file(binaryFile);
    cl::Program::Binaries bins{{fileBuf.data(), fileBuf.size()}};
    bool valid_device = false;
    for (unsigned int i = 0; i < devices.size(); i++) {
        auto device = devices[i];
        // Creating Context and Command Queue for selected Device
        OCL_CHECK(err, context = cl::Context(device, nullptr, nullptr, nullptr, &err));
        OCL_CHECK(err, q = cl::CommandQueue(context, device, 
        CL_QUEUE_OUT_OF_ORDER_EXEC_MODE_ENABLE | // dataflow
        CL_QUEUE_PROFILING_ENABLE, &err));
        std::cout << "Trying to program device[" << i << "]: " << device.getInfo<CL_DEVICE_NAME>() << std::endl;
        cl::Program program(context, {device}, bins, nullptr, &err);
        if (err != CL_SUCCESS) {
            std::cout << "Failed to program device[" << i << "] with xclbin file!\n";
        } else {
            std::cout << "Device[" << i << "]: program successful!\n";
            OCL_CHECK(err, krnl_Bert_layer_dataflow_region_1 = cl::Kernel(program, "Bert_layer_dataflow_region_1", &err));
            OCL_CHECK(err, krnl_Bert_layer_dataflow_region_2 = cl::Kernel(program, "Bert_layer_dataflow_region_2", &err));
            OCL_CHECK(err, krnl_Bert_layer_dataflow_region_3 = cl::Kernel(program, "Bert_layer_dataflow_region_3", &err));
            valid_device = true;
            break; // we break because we found a valid device
        }
    }
    if (!valid_device) {
        std::cout << "Failed to program any device found, exit!\n";
        exit(EXIT_FAILURE);
    }
    // Allocate Buffer in Global Memory
    // Buffers are allocated using CL_MEM_USE_HOST_PTR for efficient memory and
    // Device-to-host communication
    cl_mem_ext_ptr_t source_in0_hbm;
    source_in0_hbm.obj = source_in0.data();
    source_in0_hbm.param = 0;
    source_in0_hbm.flags = HBM[0];

    cl_mem_ext_ptr_t source_wk_hbm_0;
    source_wk_hbm_0.obj = source_wk_0.data();
    source_wk_hbm_0.param = 0;
    source_wk_hbm_0.flags = HBM[1];
    cl_mem_ext_ptr_t source_wk_hbm_1;
    source_wk_hbm_1.obj = source_wk_1.data();
    source_wk_hbm_1.param = 0;
    source_wk_hbm_1.flags = HBM[2];
    cl_mem_ext_ptr_t source_wv_hbm_0;
    source_wv_hbm_0.obj = source_wv_0.data();
    source_wv_hbm_0.param = 0;
    source_wv_hbm_0.flags = HBM[3];
    cl_mem_ext_ptr_t source_wv_hbm_1;
    source_wv_hbm_1.obj = source_wv_1.data();
    source_wv_hbm_1.param = 0;
    source_wv_hbm_1.flags = HBM[4];
    cl_mem_ext_ptr_t source_wq_hbm_0;
    source_wq_hbm_0.obj = source_wq_0.data();
    source_wq_hbm_0.param = 0;
    source_wq_hbm_0.flags = HBM[5];
    cl_mem_ext_ptr_t source_wq_hbm_1;
    source_wq_hbm_1.obj = source_wq_1.data();
    source_wq_hbm_1.param = 0;
    source_wq_hbm_1.flags = HBM[6];

    cl_mem_ext_ptr_t source_w_ds0_hbm_0;
    source_w_ds0_hbm_0.obj = source_w_ds0_0.data();
    source_w_ds0_hbm_0.param = 0;
    source_w_ds0_hbm_0.flags = HBM[7];
    cl_mem_ext_ptr_t source_w_ds0_hbm_1;
    source_w_ds0_hbm_1.obj = source_w_ds0_1.data();
    source_w_ds0_hbm_1.param = 0;
    source_w_ds0_hbm_1.flags = HBM[8];

    cl_mem_ext_ptr_t source_w_ds1_hbm_0;
    source_w_ds1_hbm_0.obj = source_w_ds1_0.data();
    source_w_ds1_hbm_0.param = 0;
    source_w_ds1_hbm_0.flags = HBM[9];
    cl_mem_ext_ptr_t source_w_ds1_hbm_1;
    source_w_ds1_hbm_1.obj = source_w_ds1_1.data();
    source_w_ds1_hbm_1.param = 0;
    source_w_ds1_hbm_1.flags = HBM[10];
    cl_mem_ext_ptr_t source_w_ds1_hbm_2;
    source_w_ds1_hbm_2.obj = source_w_ds1_2.data();
    source_w_ds1_hbm_2.param = 0;
    source_w_ds1_hbm_2.flags = HBM[11];
    cl_mem_ext_ptr_t source_w_ds1_hbm_3;
    source_w_ds1_hbm_3.obj = source_w_ds1_3.data();
    source_w_ds1_hbm_3.param = 0;
    source_w_ds1_hbm_3.flags = HBM[12];

    cl_mem_ext_ptr_t source_w_ds2_hbm_0;
    source_w_ds2_hbm_0.obj = source_w_ds2_0.data();
    source_w_ds2_hbm_0.param = 0;
    source_w_ds2_hbm_0.flags = HBM[13];
    cl_mem_ext_ptr_t source_w_ds2_hbm_1;
    source_w_ds2_hbm_1.obj = source_w_ds2_1.data();
    source_w_ds2_hbm_1.param = 0;
    source_w_ds2_hbm_1.flags = HBM[14];
    cl_mem_ext_ptr_t source_w_ds2_hbm_2;
    source_w_ds2_hbm_2.obj = source_w_ds2_2.data();
    source_w_ds2_hbm_2.param = 0;
    source_w_ds2_hbm_2.flags = HBM[15];
    cl_mem_ext_ptr_t source_w_ds2_hbm_3;
    source_w_ds2_hbm_3.obj = source_w_ds2_3.data();
    source_w_ds2_hbm_3.param = 0;
    source_w_ds2_hbm_3.flags = HBM[16];

    OCL_CHECK(err, cl::Buffer buffer_in0(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_in0, &source_in0_hbm, &err));
    OCL_CHECK(err, cl::Buffer buffer_wk_0(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_wk_0, &source_wk_hbm_0, &err));
    OCL_CHECK(err, cl::Buffer buffer_wk_1(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_wk_1, &source_wk_hbm_1, &err));
    OCL_CHECK(err, cl::Buffer buffer_wv_0(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_wv_0, &source_wv_hbm_0, &err));
    OCL_CHECK(err, cl::Buffer buffer_wv_1(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_wv_1, &source_wv_hbm_1, &err));
    OCL_CHECK(err, cl::Buffer buffer_wq_0(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_wq_0, &source_wq_hbm_0, &err));
    OCL_CHECK(err, cl::Buffer buffer_wq_1(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_wq_1, &source_wq_hbm_1, &err));
    OCL_CHECK(err, cl::Buffer buffer_w_ds0_0(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_w_ds0_0, &source_w_ds0_hbm_0, &err));
    OCL_CHECK(err, cl::Buffer buffer_w_ds0_1(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_w_ds0_1, &source_w_ds0_hbm_1, &err));

    OCL_CHECK(err, cl::Buffer buffer_w_ds1_0(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_w_ds1_0, &source_w_ds1_hbm_0, &err));
    OCL_CHECK(err, cl::Buffer buffer_w_ds1_1(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_w_ds1_1, &source_w_ds1_hbm_1, &err));
    OCL_CHECK(err, cl::Buffer buffer_w_ds1_2(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_w_ds1_2, &source_w_ds1_hbm_2, &err));
    OCL_CHECK(err, cl::Buffer buffer_w_ds1_3(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_w_ds1_3, &source_w_ds1_hbm_3, &err));

    OCL_CHECK(err, cl::Buffer buffer_w_ds2_0(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_w_ds2_0, &source_w_ds2_hbm_0, &err));
    OCL_CHECK(err, cl::Buffer buffer_w_ds2_1(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_w_ds2_1, &source_w_ds2_hbm_1, &err));
    OCL_CHECK(err, cl::Buffer buffer_w_ds2_2(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_w_ds2_2, &source_w_ds2_hbm_2, &err));
    OCL_CHECK(err, cl::Buffer buffer_w_ds2_3(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, size_bytes_w_ds2_3, &source_w_ds2_hbm_3, &err));
    // OCL_CHECK(err, cl::Buffer buffer_out0(context, CL_MEM_USE_HOST_PTR | CL_MEM_WRITE_ONLY, size_bytes_out0, source_out0.data(), &err));
    OCL_CHECK(err, cl::Buffer buffer_out0(context, CL_MEM_EXT_PTR_XILINX | CL_MEM_USE_HOST_PTR | CL_MEM_WRITE_ONLY, size_bytes_in0, &source_in0_hbm, &err));

    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_1.setArg(0, buffer_in0));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_1.setArg(1, buffer_in0));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_1.setArg(2, buffer_in0));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_1.setArg(3, buffer_wk_0));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_1.setArg(4, buffer_wk_1));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_1.setArg(5, buffer_wv_0));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_1.setArg(6, buffer_wv_1));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_1.setArg(7, buffer_wq_0));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_1.setArg(8, buffer_wq_1));

    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_2.setArg(0, buffer_w_ds0_0));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_2.setArg(1, buffer_w_ds0_1));

    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_3.setArg(0, buffer_w_ds1_0));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_3.setArg(1, buffer_w_ds1_1));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_3.setArg(2, buffer_w_ds1_2));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_3.setArg(3, buffer_w_ds1_3));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_3.setArg(4, buffer_w_ds2_0));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_3.setArg(5, buffer_w_ds2_1));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_3.setArg(6, buffer_w_ds2_2));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_3.setArg(7, buffer_w_ds2_3));
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_3.setArg(9, buffer_out0));
    
    cl::Event event;
    uint64_t nstimestart, nstimeend;
    uint64_t exe_time = 0;

    //single token
    // Copy input data to device global memory
    std::cout << "|-------------------------+-------------------------|\n"
              << "| Single Token            |    Wall-Clock Time (ns) |\n"
              << "|-------------------------+-------------------------|\n";

    OCL_CHECK(err, err = q.enqueueMigrateMemObjects({buffer_in0}, 0 /* 0 means from host*/));
    q.finish();

    // Launch the Kernel
    OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_2.setArg(7, 63));
    OCL_CHECK(err, err = q.enqueueTask(krnl_Bert_layer_dataflow_region_1, nullptr, &event));
    OCL_CHECK(err, err = q.enqueueTask(krnl_Bert_layer_dataflow_region_2, nullptr, &event));
    OCL_CHECK(err, err = q.enqueueTask(krnl_Bert_layer_dataflow_region_3, nullptr, &event));
    q.finish();

    // Copy Result from Device Global Memory to Host Local Memory
    OCL_CHECK(err, err = q.enqueueMigrateMemObjects({buffer_out0}, CL_MIGRATE_MEM_OBJECT_HOST));
    q.finish();
    // OpenCL Host Code Ends

    // Get the execution time
    OCL_CHECK(err, err = event.getProfilingInfo<uint64_t>(CL_PROFILING_COMMAND_START, &nstimestart));
    OCL_CHECK(err, err = event.getProfilingInfo<uint64_t>(CL_PROFILING_COMMAND_END, &nstimeend));
    exe_time = nstimeend - nstimestart;
    std::cout << "| " << std::left << std::setw(24) << "Bert_layer: "
              << "|" << std::right << std::setw(24) << exe_time << " |\n";
    std::cout << "|-------------------------+-------------------------|\n\n";


    //multi layer
    // Copy input data to device global memory
    std::cout << "|-------------------------+-------------------------|\n"
              << "| Multi Layer             |    Wall-Clock Time (ns) |\n"
              << "|-------------------------+-------------------------|\n";

    OCL_CHECK(err, err = q.enqueueMigrateMemObjects({buffer_in0}, 0 /* 0 means from host*/));
    q.finish();

    // Launch the Kernel
    exe_time = 0;
    for(int i=0; i<32; i++){
        for(int j=0; j<512; j++){
            OCL_CHECK(err, err = krnl_Bert_layer_dataflow_region_2.setArg(7, j));
            OCL_CHECK(err, err = q.enqueueTask(krnl_Bert_layer_dataflow_region_1, nullptr, &event));
            OCL_CHECK(err, err = q.enqueueTask(krnl_Bert_layer_dataflow_region_2, nullptr, &event));
            OCL_CHECK(err, err = q.enqueueTask(krnl_Bert_layer_dataflow_region_3, nullptr, &event));
            q.finish();
            OCL_CHECK(err, err = event.getProfilingInfo<uint64_t>(CL_PROFILING_COMMAND_START, &nstimestart));
            OCL_CHECK(err, err = event.getProfilingInfo<uint64_t>(CL_PROFILING_COMMAND_END, &nstimeend));
            exe_time += nstimeend - nstimestart;
        }
    }

    // Copy Result from Device Global Memory to Host Local Memory
    OCL_CHECK(err, err = q.enqueueMigrateMemObjects({buffer_out0}, CL_MIGRATE_MEM_OBJECT_HOST));
    q.finish();
    // OpenCL Host Code Ends

    // Get the execution time
    std::cout << "| " << std::left << std::setw(24) << "Bert_layer: "
              << "|" << std::right << std::setw(24) << exe_time << " |\n";
    std::cout << "|-------------------------+-------------------------|\n";
    std::cout << "Note: Wall Clock Time is meaningful for real hardware execution "
              << "only, not for emulation.\n";
    std::cout << "Please refer to profile summary for kernel execution time for "
              << "hardware emulation.\n";
    std::cout << "TEST PASSED\n\n";
    return EXIT_SUCCESS;
}